# 《大数据系统基础》期末大作业实验报告

**项目名称**：基于 Hadoop 生态系统的分布式校园文档搜索引擎  
**项目成员**：[此处填入你的名字]  
**完成时间**：2026年1月16日  

---

## 1. 小组成员名单与具体分工

本项目由单人独立完成。

- **[你的名字]**：负责需求分析、爬虫系统开发、HDFS/HBase 存储架构设计、NLP 关键词抽取算法实现、Flask Web 检索系统搭建以及实验报告撰写。

---

## 2. 技术路线

本项目构建了一套从数据采集、流式清洗、分布式存储到加权检索的全链路系统，核心技术选型紧扣大数据课程主题：

### 2.1 分布式存储层（课程核心技术）
- **HDFS (Hadoop Distributed File System)**：用于存储海量的原始文档二进制文件（PDF、DOCX 等）。利用 HDFS 的高容错性和横向扩展能力，解决校园海量文档的物理存储问题。
- **HBase (NoSQL Database)**：构建索引层。将文档的元数据（URL、标题、采集日期）、摘要内容以及关键词索引存储在 HBase 中。利用其列族（Column Family）特性，实现元数据与正文内容的逻辑隔离与快速随机读写。

### 2.2 数据采集与处理层
- **自适应爬虫**：基于 Python 开发，采用 BFS（广度优先搜索）算法发现校内链接。针对服务器反爬限制，实现了**指数退避重试**与**自适应休眠**机制。
- **NLP 处理 (Jieba + TF-IDF)**：在数据入库前进行在线处理。利用 Jieba 分词提取文档前 5 个核心关键词，并对正文进行流式解析（pdfplumber / python-docx），实现数据在内存中的即时清洗，避免磁盘 I/O 损耗。

### 2.3 Web 检索与应用层
- **Flask 框架**：搭建轻量级搜索门户。
- **三维加权排序算法**：自主设计了结合“标题命中 + 关键词相关性 + 词频统计”的评分模型，模拟真实搜索引擎的排序逻辑。
- **跨系统管道下载**：实现从 Web 后端通过标准输入输出流（WSL Pipe）直接读取 HDFS 数据并返回给用户的流式下载功能。

---

## 3. 实现功能介绍与效果展示

### 3.1 核心功能
1.  **全量数据采集**：覆盖教务处、研究生院等核心部门，自动化抓取数千份学术文档。
2.  **分布式去重存储**：基于 URL 的 MD5 哈希作为 HBase RowKey，确保数据不重复。
3.  **多维度精准检索**：支持对标题、正文和提取的关键词进行综合匹配。
4.  **智能摘要生成**：在结果页动态展示搜索词周边的上下文内容并实现高亮。
5.  **无感式文件下载**：用户可直接通过 Web 界面一键下载存储在远程 HDFS 中的文件。

### 3.2 效果展示
*(此处建议根据你的运行结果补充截图描述)*
- **搜索首页**：简洁的类 Google 搜索框。
- **搜索结果页**：展示文件标题、相关度得分、抓取日期、关键词标签以及高亮显示的文本摘要。
- **HBase 状态**：通过 `scan` 命令展示 HBase 中存储的结构化元数据。

---

## 4. 核心代码块

### 4.1 爬虫自适应退避逻辑 (防封锁关键)
```python
# 当检测到 WinError 10053 (服务器强制切断连接) 时触发熔断
except Exception as e:
    if "10053" in str(e) or "Connection aborted" in str(e):
        logger.warning("检测到连接被重置，触发熔断机制。休眠 60s 后重试...")
        time.sleep(60) # 模拟人类浏览停顿，规避封禁
    pass
```

### 4.2 三维加权排序模型
```python
# 相关度计分 = 标题命中(100) + 关键词命中(50) + 词频微调(1-20)
score = 0
if query in title:
    score += 100
if query in keywords_list:
    score += 50
term_count = content.count(query)
score += min(term_count, 20) # 限制词频上限，防止 SEO 灌水
```

### 4.3 跨系统流式存储 (WSL + HDFS Pipe)
```python
# 通过管道直接将二进制流传输给 HDFS，实现数据不落地磁盘
cmd_str = f'wsl {Config.HDFS_BIN} dfs -put -f - "{hdfs_path}"'
process = subprocess.Popen(cmd_str, shell=True, stdin=subprocess.PIPE, ...)
stdout, stderr = process.communicate(input=content)
```

---

## 5. 总结与心得

### 5.1 踩坑与错误总结
1.  **连接稳定性问题**：在实验初期，高频爬取导致学校服务器频繁抛出 `10053` 错误。通过引入 `random.uniform` 随机延时和异常捕获熔断机制，最终实现了无人值守的稳定采集。
2.  **编码一致性**：在 HDFS 与 HBase 交互过程中，由于文件名包含特殊字符和中文，导致了多次 `UnicodeEncodeError`。心得：在所有分布式组件交互时，务必统一使用 UTF-8 编码并添加 `ignore` 错误处理策略。
3.  **WSL 环境隔离**：由于 Hadoop 运行在 WSL 虚拟环境中，Windows 上的 Python 无法直接调用命令。最终通过 `subprocess` 调用 `wsl` 指令解决了跨系统的文件传输问题。

### 5.2 实验收获
通过本次大作业，我系统地实践了 Hadoop 生态中的 HDFS 与 HBase 核心技术。我认识到，一个真正的“大数据”系统，核心挑战不仅在于存储规模，更在于如何优雅地处理非结构化数据（文档）以及如何在海量数据中实现低延迟的检索响应。

从手动搭建 Hadoop 集群到实现全自动化的搜索门户，这段从底层存储到上层应用的开发过程，极大地提升了我对分布式系统的一致性、容错性以及性能调优的理解。

---

1. **内存解析**：
爬虫拿到的二进制流（Bytes），我直接在内存中用 `pdfplumber`（针对 PDF）和 `python-docx`（针对 Word）提取出纯文本内容。
1. **特征工程 (NLP)**：
拿到文本后，我立即调用 `jieba` 分词组件。
* 利用 **TF-IDF 算法**，实时计算出这篇文档的 **Top 5 核心关键词**（例如“奖学金”、“答辩”、“转专业”）。
* 这些关键词标签，后续将成为我们搜索排序的重要权重依据。



---

## 第三步：跨系统数据管道 (The Memory Pipe)


我的开发环境是 Windows，而 Hadoop 集群运行在 WSL (Linux) 子系统里。
如果采用“下载到本地 -> 复制到 WSL -> 上传 HDFS”的传统方式，IO 开销巨大。

我构建了一个**“跨系统内存管道”**：

* 利用 Python 的 `subprocess` 模块，我直接调用 WSL 里的 `hdfs dfs -put -` 命令。
* 将内存里的文件流，通过标准输入（STDIN）直接“喷”进 Linux 的 HDFS 里。
* 实现了数据的**零拷贝、零落地**传输，极大提升了写入吞吐量。
* *核心代码片段：*

```python
cmd = f'wsl /opt/module/hadoop/bin/hdfs dfs -put - "{hdfs_dest}"'
process = subprocess.Popen(cmd, shell=True, stdin=subprocess.PIPE, ...)
# 直接将内存中的 bytes 写入管道
process.communicate(input=content)

```

---

## 第四步：双库异构存储架构 (Storage Architecture)

在存储层面，为了避免数据库臃肿，我设计了**“元数据与实体分离”**的架构：

1. **HDFS（负责存文件本体）**：
* 我计算文件内容的 **MD5 哈希值**作为文件名（如 `d41d8c...pdf`）。
* 这天然实现了**全局去重 (Deduplication)**：不同学院发的同一份文件，在底层只存一份。


2. **HBase（负责存相关信息）**：
* RowKey 设计为 `MD5(URL)`，保证散列均匀。
* 表结构分为三个列族：
* `meta`: 存标题、日期、URL。
* `data`: 存纯文本内容（用于搜索）和 HDFS 路径（用于下载）。
* `index`: 存刚才算好的 Top 5 关键词（用于加权）。





---

## 第五步：三维加权排序算法 (Ranking Algorithm)


接下来是**后端检索**逻辑。
为了解决“能搜到但排不准”的问题，我放弃了简单的布尔查询，实现了一套**“三维加权排序算法”**。

当用户输入一个查询词时，系统会遍历 HBase 索引，并计算每个文档的 **Relevance Score（契合度分数）**：

* **维度一（统治级权重）**：**标题命中 (+100分)**。标题里有词，说明它是核心文档。
* **维度二（语义权重）**：**关键词命中 (+50分)**。如果命中离线计算的 Top 5 标签，说明它在语义上高度相关。
* **维度三（辅助权重）**：**正文词频 (+1分)**。正文里提到的次数越多，分数越高（设上限防止灌水）。

最后，系统按总分降序排列，确保用户最想要的“通知原件”永远排在第一位。

---

## 第六步：应用层交互 (Application & UI)

**[Slide 7: 分页与流式下载]**



1. **内存分页 (Pagination)**：
后端算出所有结果的排序后，采用内存切片的方式，向前端返回当前页的 10 条数据，支持翻页浏览。
1. **智能摘要**：
自动定位关键词在正文中的位置，截取前后 100 字，并对关键词进行**高亮显示**。
1. **流式下载 (Streaming Download)**：
当用户点击下载时，后端根据 HBase 里的路径，去 HDFS 读取那个哈希名的文件流，并在传输给浏览器时，将文件名**还原为原始中文名**。用户对此过程无感知，体验非常流畅。

---

## 总结 (Conclusion)



综上所述，我完成了一个**闭环**的分布式搜索系统。
从爬虫的**自适应对抗**，到传输的**内存管道**，再到存储的**去重架构**和检索的**加权算法**，每一个环节都经过了工程化的思考与优化。

这就是我的汇报，感谢聆听。
